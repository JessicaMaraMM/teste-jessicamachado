# TESTE 1 - INTEGRA√á√ÉO COM API P√öBLICA
# Autora: J√©ssica Mara de Morais Machado
# Objetivo: Download, extra√ß√£o e consolida√ß√£o de Demonstra√ß√µes Cont√°beis

# Bibliotecas

import pandas as pd
import requests
from pathlib import Path
import zipfile
from bs4 import BeautifulSoup

# Configura√ß√µes

URL_BASE = "https://dadosabertos.ans.gov.br/FTP/PDA/"

# Trimestres definidos manualmente
ANO = "2025"
TRIMESTRES = ["1T2025", "2T2025", "3T2025"]

PASTA_ATUAL = Path(__file__).parent
PASTA_DOWNLOADS = PASTA_ATUAL / "downloads"
PASTA_EXTRAIDOS = PASTA_ATUAL / "extra√≠dos"
PASTA_PROCESSADOS = PASTA_ATUAL / "processados"

# Fun√ß√µes

def criar_estrutura_pastas():
    """Cria pastas: downloads/, extra√≠dos/, processados/."""
    print("üìÅ Estrutura de pastas")

    PASTA_DOWNLOADS.mkdir(exist_ok=True)
    PASTA_EXTRAIDOS.mkdir(exist_ok=True)
    PASTA_PROCESSADOS.mkdir(exist_ok=True)

    print("‚úÖ Pastas criadas\n")


def encontrar_pasta_demonstracoes():
    """Navega pelo FTP da ANS e retorna URL da pasta demonstracoes_contabeis."""
    print("üîç FTP ANS")

    try:
        resposta = requests.get(URL_BASE, timeout=30)
        resposta.raise_for_status()

        soup = BeautifulSoup(resposta.text, 'html.parser')

        for link in soup.find_all('a'):
            href = link.get('href')
            if href and 'demonstracoes_contabeis' in href.lower():
                pasta_url = f"{URL_BASE}{href}"
                print(f"  ‚úÖ Encontrada: {href}")
                return pasta_url

        print("  ‚ùå Pasta 'demonstracoes_contabeis' n√£o encontrada!")
        return None

    except Exception as erro:
        print(f"  ‚ùå Erro ao navegar pelo FTP: {erro}")
        return None


def baixar_arquivos_zip():
    """Baixa os ZIPs dos trimestres especificados via HTTP."""
    print("üì• Download ZIP")

    pasta_demonstracoes = encontrar_pasta_demonstracoes()

    if not pasta_demonstracoes:
        print("  ‚ùå N√£o foi poss√≠vel encontrar a pasta de demonstra√ß√µes!")
        return

    for trimestre in TRIMESTRES:
        url = f"{pasta_demonstracoes}{ANO}/{trimestre}.zip"
        nome_arquivo = f"{trimestre}.zip"
        caminho_destino = PASTA_DOWNLOADS / nome_arquivo

        print(f"  üîΩ {trimestre}")

        try:
            resposta = requests.get(url, timeout=30)
            resposta.raise_for_status()

            with open(caminho_destino, 'wb') as arquivo:
                arquivo.write(resposta.content)

            print(f"  ‚úÖ {nome_arquivo}")

        except Exception as erro:
            print(f"  ‚ùå Erro ao baixar {trimestre}: {erro}")

    print()


def extrair_arquivos_zip():
    """Extrai todos os arquivos ZIP baixados."""
    print("üì¶ Extra√ß√£o ZIP")

    arquivos_zip = list(PASTA_DOWNLOADS.glob("*.zip"))
    if not arquivos_zip:
        print("  ‚ö†Ô∏è Nenhum arquivo ZIP encontrado na pasta downloads!")
        return

    for arquivo_zip in arquivos_zip:
        print(f"  üìÇ {arquivo_zip.name}")
        try:
            with zipfile.ZipFile(arquivo_zip, 'r') as zip_ref:
                zip_ref.extractall(PASTA_EXTRAIDOS)
            print(f"  ‚úÖ {arquivo_zip.name}")
        except Exception as erro:
            print(f"  ‚ùå Erro ao extrair {arquivo_zip.name}: {erro}")

    print()


def identificar_arquivos_despesas():
    """Busca arquivos por palavras-chave: despesa, evento, sinistro."""
    print("üîç Arquivos Despesas")

    arquivos_despesas = []
    palavras_chave = ['despesa', 'evento', 'sinistro']

    for arquivo in PASTA_EXTRAIDOS.rglob("*"):
        if arquivo.is_file():
            nome_arquivo_minusculo = arquivo.name.lower()

            if any(palavra in nome_arquivo_minusculo for palavra in palavras_chave):
                arquivos_despesas.append(arquivo)
                print(f"  ‚úÖ {arquivo.name}")

    if not arquivos_despesas:
        print("  ‚ö†Ô∏è Nenhum arquivo com palavras-chave")
        print("  üîÑ Processando todos CSV/TXT/XLSX")

        extensoes_validas = ['.csv', '.txt', '.xls', '.xlsx']
        for arquivo in PASTA_EXTRAIDOS.rglob("*"):
            if arquivo.is_file() and arquivo.suffix.lower() in extensoes_validas:
                arquivos_despesas.append(arquivo)
                print(f"  ‚úÖ {arquivo.name}")

    if arquivos_despesas:
        print(f"  ‚úÖ Total: {len(arquivos_despesas)}")
    else:
        print("  ‚ö†Ô∏è Nenhum arquivo v√°lido")

    print()
    return arquivos_despesas


def processar_arquivo(caminho_arquivo):
    """L√™ arquivo CSV/TXT/XLSX e retorna DataFrame."""
    print(f"üìÑ {caminho_arquivo.name}")

    try:
        extensao = caminho_arquivo.suffix.lower()

        if extensao == '.csv':
            df = pd.read_csv(caminho_arquivo, encoding='utf-8', sep=';')
        elif extensao == '.txt':
            df = pd.read_csv(caminho_arquivo, encoding='utf-8', sep='\t')
        elif extensao in ['.xls', '.xlsx']:
            df = pd.read_excel(caminho_arquivo, engine='openpyxl')
        else:
            print(f"  ‚ö†Ô∏è Formato de arquivo n√£o suportado: {extensao}")
            return None

        print(f"  ‚úÖ {len(df)} linhas, {len(df.columns)} colunas")
        return df

    except Exception as erro:
        print(f"  ‚ùå Erro ao processar {caminho_arquivo.name}: {erro}")
        return None


def consolidar_dados(lista_arquivos):
    """Processa e junta todos os arquivos em um √∫nico DataFrame."""
    print("üìä Consolida√ß√£o")

    lista_dataframes = []

    for arquivo in lista_arquivos:
        df = processar_arquivo(arquivo)

        if df is not None:
            df['arquivo_origem'] = arquivo.name
            lista_dataframes.append(df)

    if not lista_dataframes:
        print("  ‚ùå Nenhum arquivo foi processado com sucesso!")
        return None

    df_consolidado = pd.concat(lista_dataframes, ignore_index=True)

    print(f"  ‚úÖ {len(df_consolidado)} registros, {len(df_consolidado.columns)} colunas, {len(lista_dataframes)} arquivos\n")

    return df_consolidado


def normalizar_colunas(df):
    """
    Padroniza colunas: REG_ANS, CNPJ, RazaoSocial, Ano, Trimestre,
    ValorDespesas, FlagValorSuspeito, FlagDuplicado.
    """
    print("üîÑ Normaliza√ß√£o")

    df_normalizado = df.copy()

    if 'REG_ANS' not in df_normalizado.columns:
        print("  ‚ö†Ô∏è Coluna REG_ANS n√£o encontrada!")
        df_normalizado['REG_ANS'] = pd.NA

    if 'CNPJ' not in df_normalizado.columns:
        df_normalizado['CNPJ'] = pd.NA
        print("  ‚ö†Ô∏è Coluna CNPJ n√£o encontrada nos dados - preenchida com NULL")

    if 'RazaoSocial' not in df_normalizado.columns and 'Razao_Social' not in df_normalizado.columns:
        df_normalizado['RazaoSocial'] = pd.NA
        print("  ‚ö†Ô∏è Coluna RazaoSocial n√£o encontrada nos dados - preenchida com NULL")

    elif 'Razao_Social' in df_normalizado.columns:
        df_normalizado['RazaoSocial'] = df_normalizado['Razao_Social']

    if 'arquivo_origem' in df_normalizado.columns:
        df_normalizado['Trimestre'] = df_normalizado['arquivo_origem'].str.extract(
            r'(\dT)', expand=False)
        df_normalizado['Ano'] = df_normalizado['arquivo_origem'].str.extract(
            r'(20\d{2})', expand=False)
    else:
        df_normalizado['Trimestre'] = 'N/A'
        df_normalizado['Ano'] = '2025'

    if 'VL_SALDO_FINAL' in df_normalizado.columns:
        df_normalizado['ValorDespesas'] = pd.to_numeric(
            df_normalizado['VL_SALDO_FINAL'], errors='coerce')
        df_normalizado['ValorDespesas'] = df_normalizado['ValorDespesas'].fillna(
            0.0)
    else:
        print("  ‚ö†Ô∏è Coluna VL_SALDO_FINAL n√£o encontrada!")
        df_normalizado['ValorDespesas'] = 0.0

    df_normalizado['FlagValorSuspeito'] = False
    df_normalizado['FlagDuplicado'] = False

    colunas_finais = [
        'REG_ANS', 'CNPJ', 'RazaoSocial', 'Ano', 'Trimestre',
        'ValorDespesas', 'FlagValorSuspeito', 'FlagDuplicado'
    ]

    df_final = df_normalizado[colunas_finais]

    print(f"  ‚úÖ Colunas normalizadas: {', '.join(colunas_finais)}")
    print()

    return df_final


def marcar_valores_suspeitos(df):
    """Marca valores <= 0 como suspeitos. Mant√©m valores originais."""
    print("üîç Valores suspeitos")

    df_marcado = df.copy()

    df_marcado['FlagValorSuspeito'] = (df_marcado['ValorDespesas'] <= 0) | (
        df_marcado['ValorDespesas'].isna())

    total_suspeitos = df_marcado['FlagValorSuspeito'].sum()
    total_negativos = (df_marcado['ValorDespesas'] < 0).sum()
    total_zerados = (df_marcado['ValorDespesas'] == 0).sum()

    print(f"  üìã Valores negativos: {total_negativos}")
    print(f"  üìã Valores zerados: {total_zerados}")
    print(f"  üìã Total suspeitos: {total_suspeitos}")
    print()

    return df_marcado


def detectar_duplicatas_suspeitas(df):
    """
    Detecta registros id√™nticos ou com REG_ANS+per√≠odo+valor duplicados.
    Nota: REG_ANS pode repetir no mesmo per√≠odo (m√∫ltiplas contas cont√°beis).
    """
    print("üîç Duplicatas")

    df_resultado = df.copy()

    dup_total = df_resultado.duplicated(keep=False)

    dup_logica = df_resultado.duplicated(
        subset=['REG_ANS', 'Ano', 'Trimestre', 'ValorDespesas'],
        keep=False
    )

    df_resultado['FlagDuplicado'] = dup_total | dup_logica

    total_duplicados = df_resultado['FlagDuplicado'].sum()

    if total_duplicados > 0:
        print(f"  ‚ö†Ô∏è {total_duplicados} duplicatas")
    else:
        print("  ‚úÖ Sem duplicatas")

    print()
    return df_resultado


def exportar_resultado(df):
    """Exporta DataFrame em CSV e ZIP com estat√≠sticas."""
    print("üíæ Exporta√ß√£o")

    try:
        caminho_csv = PASTA_PROCESSADOS / "consolidado_despesas.csv"
        caminho_zip = PASTA_PROCESSADOS / "consolidado_despesas.zip"

        df.to_csv(caminho_csv, index=False, encoding='utf-8-sig', sep=';')
        print(f"  ‚úÖ {caminho_csv.name}")

        with zipfile.ZipFile(caminho_zip, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            zip_file.write(caminho_csv, arcname="consolidado_despesas.csv")
        print(f"  ‚úÖ {caminho_zip.name}\n")

        total_registros = len(df)
        total_suspeitos = df['FlagValorSuspeito'].sum()
        total_duplicados = df['FlagDuplicado'].sum()
        total_ok = ((~df['FlagValorSuspeito']) & (~df['FlagDuplicado'])).sum()

        print(f"\nüìä RESUMO:")
        print(f"  üìÅ {PASTA_PROCESSADOS}")
        print(f"  üìÑ Total de registros: {total_registros}")
        print(f"  ‚úÖ Registros OK: {total_ok}")
        print(f"  ‚ö†Ô∏è  Valores suspeitos: {total_suspeitos}")
        print(f"  ‚ö†Ô∏è  Duplicatas suspeitas: {total_duplicados}")
        print()

        return True

    except Exception as erro:
        print(f"  ‚ùå Erro ao exportar resultados: {erro}")
        return False

# Main

def main():

    print("="*60)
    print("TESTE 1 - INTEGRA√á√ÉO COM API ANS")
    print("Processamento de Demonstra√ß√µes Cont√°beis")
    print("="*60)
    print()

    try:
        criar_estrutura_pastas()
        baixar_arquivos_zip()
        extrair_arquivos_zip()

        arquivos_despesas = identificar_arquivos_despesas()

        if not arquivos_despesas:
            print("‚ùå Nenhum arquivo de despesas encontrado. Encerrando processo.")
            return

        df_consolidado = consolidar_dados(arquivos_despesas)

        if df_consolidado is None:
            print("‚ùå Falha na consolida√ß√£o dos dados. Encerrando processo.")
            return

        df_normalizado = normalizar_colunas(df_consolidado)
        df_com_flags_valor = marcar_valores_suspeitos(df_normalizado)
        df_final = detectar_duplicatas_suspeitas(df_com_flags_valor)

        sucesso = exportar_resultado(df_final)

        if sucesso:
            print("="*60)
            print("‚úÖ PROCESSAMENTO CONCLU√çDO")
            print("="*60)
            print(f"\nüìÅ {PASTA_PROCESSADOS}")
            print("üìÑ consolidado_despesas.zip")
            print()
        else:
            print("‚ö†Ô∏è Processamento com erros")

    except Exception as erro:
        print(f"\n‚ùå ERRO CR√çTICO: {erro}")
        print("Encerrando processamento.")
        import traceback
        traceback.print_exc()

# Executar


if __name__ == "__main__":
    main()
